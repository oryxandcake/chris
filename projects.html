<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> | </title>
  <link rel="stylesheet" href="/assets/style.css">
  <link rel="stylesheet" href="/assets/custom.css"><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
<script>
  (function() {
    const storedTheme = localStorage.getItem('theme');
    if (storedTheme) {
      document.documentElement.setAttribute('data-theme', storedTheme);
    } else {
      document.documentElement.setAttribute('data-theme', 'light');
    }
  })();
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> 
</head>
<body>
  <header class="site-header">
  <nav class="nav">
    <ul id="nav-links" class="nav-links">
      <li><a href="/" class="">home</a></li>
      <li><a href="/blog/" class="">blog</a></li>
      <li><a href="/projects/" class="active">projects</a></li>
      <li><a href="/about/" class="">about</a></li>
      <li><a href="/contact/" class="">contact</a></li>
    </ul>
  </nav>
</header>

  <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">üåô</button>

  <main class="container">
    <article>
  <header>
    <h1></h1>
  </header>
  <p>Research Ready Intern - Google DeepMind (with University of Exeter)</p>

<p>Worked on ‚ÄúScientific Paper Understanding with Multimodal LLMs and Knowledge Graphs‚Äù under the supervision of Dr. Hang Dong and Dr. Zhang Guioqang. Developed and evaluated methods to improve the quality and contextual accuracy of image captioning for figures within scientific papers. Worked with multimodal architectures to bridge the gap between visual (figures, graphs) and textual (paper content) information. Designed prompt sets and a human evaluation rubric for scientific-figure captioning; piloted LLM-as-judge checks for factual consistency. Built a lightweight evaluation harness for output correctness (batch runs, scoring, error taxonomy, reporting) to surface failure modes. See the poster <a href="/assets/documents/gdrr_presentation_final.pdf" title="Open poster (PDF)">here</a>.</p>

<p>Muse</p>

<p>Designed, built, and managed a natural-language + multimodal search turning a few image/text references into curated adjacent inspirations. Implemented vibe-first retrieval with embeddings and lightweight descriptors; hybrid queries and diversity re-rank for fuzzy, intuitive exploration. Delivered branching exploration and reproducible recipes (blend/regenerate, scope, minimum score, pin/ban) with deduplication and session memory. See the demo <a href="https://x.com/NidarMMV2/status/1979575926515257700" title="Open demo on X">here</a>.</p>

<p><a href="https://patinasystems.com/">Patina Systems</a> - Location-Based Image Matching API</p>

<p>Designed a FastAPI microservice that performs geospatially-aware image matching as a core product component for a stealth-mode startup. Implemented GPU-accelerated feature extraction and approximate nearest-neighbour search for real-time image matching capabilities. Delivered full technical documentation and hand-off while maintaining NDA confidentiality throughout the development process.</p>

<p><a href="https://pagerift.com/">Pagerift</a> - Creative Writing LLM Fine-Tuning</p>

<p>Fine-tuned a Large Language Model (Gemma 3) specifically for creative story writing, optimising the model for narrative coherence and stylistic consistency. Integrated the DSPy framework to improve model output quality through structured prompting and automated optimization techniques. Provided comprehensive consulting on backend development architecture and scalable ML deployment strategies. Developed custom evaluation metrics for creative writing quality assessment and iterative model improvement.</p>

<p>BSc Dissertation - Automatic Detection of Diabetic Retinopathy on Edge Devices</p>

<p>Investigated and compared Vision Transformer (ViT) and CNN architectures for detecting diabetic retinopathy, focusing on deployment to resource-constrained hardware. Designed and implemented robust data-gathering and preprocessing pipelines for large-scale retinal image datasets to ensure valid training and evaluation splits. Applied model optimisation techniques, including quantisation and pruning, to reduce model size and enable efficient inference on embedded devices. Authored a formal dissertation covering methodology, experimental analysis, results, and deployment lessons learned.</p>

<p>No Stylist</p>

<p>Helped build the machine-learning backend for a fashion application, handling large-scale image processing and similarity matching. Designed and implemented a product-similarity image-retrieval model using ResNet-50, experimenting with contrastive and triplet loss functions to achieve higher accuracy. Developed a core feature using a YOLOv8n model for clothing detection in user-uploaded images, enabling automated fashion item categorization. Optimised large-scale image datasets and leveraged high-performance GPUs for model training and deployment. Experimented with a sophisticated user avatar generation pipeline by chaining multiple deep learning models, including pose estimation, facial landmark detection, and generative adversarial networks for realistic avatar synthesis.</p>

<p>See the demo <a href="https://youtube.com/shorts/Wo5HfW8VT20?feature=share" title="Open demo on YouTube">here</a>.</p>


</article>

  </main>
  

  <script src="/assets/js/main.js" defer></script>
</body>
</html>
